{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aKr4SC0U-kn"
      },
      "source": [
        "# Assignment 3: Classification with Logistic Regression\n",
        "\n",
        "# Total: /100\n",
        "\n",
        "## Instructions\n",
        "\n",
        "* Complete the assignment\n",
        "\n",
        "* Once the notebook is complete, restart your kernel and rerun your cells\n",
        "\n",
        "* Submit this notebook to owl by the deadline\n",
        "\n",
        "* You may use any python library functions you wish to complete the assignment.\n",
        "\n",
        "## The Dataset\n",
        "\n",
        "The goal of our classifier is to predict, using a logistic regression, if a patient may take a certain drug.\n",
        "\n",
        "The dataset contains both numerical and categorical input variables, while the response variable ('Drug') has multiple levels. To simplify our analysis here, we focus on predicting if a patient may take \"Drug-Y\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oYk5_SCPU-kw"
      },
      "outputs": [],
      "source": [
        "# You may need these\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml # a helper function to download popular datasets\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "seed=0\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axyFmaF8U-kz"
      },
      "source": [
        "## Question 1: /18 pts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm0M4J0WU-k3"
      },
      "source": [
        "1. Read in the `drug.csv` dataset and display the first 5 rows.\n",
        "2. Print out all columns in the dataset and list categorical variables. Use the build-in function `get_dummies()` to convert all categorical variables (**exclude Drug variable**) to dummy variables. You may read the official explanations for more information on `get_dummies()` [here](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html). What's the size of the dataframe after transforming it?\n",
        "3. Map the target values from yes/no to 1/0. What is the baseline accuracy for this classification problem? Round into 1 decimal place (for example, 50.1% or 0.501)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cNADOoXU-k6"
      },
      "source": [
        "1.1 Read the dataset and display the first 8 rows, and print out all columns in the dataset and **list** all categorical variables in the answer part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAV0h1zoU-k8",
        "outputId": "8024c9f2-ef80-42b6-a479-ccfd89e2e4a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Age  Sex      BP Cholesterol  Na_to_K   Drug\n",
            "0   23    F    HIGH        HIGH   25.355  DrugY\n",
            "1   47    M     LOW        HIGH   13.093  DrugY\n",
            "2   47    M     LOW        HIGH   10.114  DrugY\n",
            "3   28    F  NORMAL        HIGH    7.798  drugX\n",
            "4   61    F     LOW        HIGH   18.043  DrugY\n",
            "5   22    F  NORMAL        HIGH    8.607  drugX\n",
            "6   49    F  NORMAL        HIGH   16.275  DrugY\n",
            "7   41  NaN     LOW        HIGH   11.037  drugC\n",
            "Index(['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Question 1.1 code here\n",
        "x = pd.read_csv(\"/content/drug.csv\")\n",
        "print(x[0:8])\n",
        "print(x.columns)\n",
        "#5 pts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL9tqfndpRbI"
      },
      "source": [
        "**YOUR ANSWER HERE:** [1pt] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HmYB6vbUeXbX"
      },
      "outputs": [],
      "source": [
        "# Sex, BP, Cholesterol, and drug are all categorical variabls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2W98Z97mfxI"
      },
      "source": [
        "1.2 Check that is any there missing value in each column of the dataset.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLp-EpaFnIYm",
        "outputId": "cf8347ed-11fb-4735-bcbc-1151f382e276"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Age            0\n",
              "Sex            3\n",
              "BP             0\n",
              "Cholesterol    0\n",
              "Na_to_K        0\n",
              "Drug           0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Question 1.2 code here\n",
        "x.isna().sum()\n",
        "#2 pts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTIk_tnonYFR"
      },
      "source": [
        "1.3 Replace all the missing values in **Sex** to be 'M'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J6s1do3KoOmU"
      },
      "outputs": [],
      "source": [
        "# Question 1.3 code here\n",
        "x = x.fillna('M')\n",
        "#2 pts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UXEH2aKU-k-"
      },
      "source": [
        "1.4 Use the build-in function `get_dummies()` to convert all categorical variables (**excluding `Drug` variable**) to dummy variables. What's the size of the dataframe after transforming?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-dsj9mrU-lA",
        "outputId": "61185a61-f6f4-40bd-cd46-c773873b9236",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The size of the data after transform is  200  rows\n"
          ]
        }
      ],
      "source": [
        "# Question 1.4 code here\n",
        "dummies = pd.get_dummies(x.drop(columns=\"Drug\", axis='columns'))\n",
        "print(\"The size of the data after transform is \", len(dummies), \" rows\")\n",
        "#2 pts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krlMrqnIU-lK"
      },
      "source": [
        "**YOUR ANSWER HERE:** [1pt] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbsurWVJq7IY"
      },
      "source": [
        "1.5 Transform all the labels that are 'DrugY' in **`Drug`** to be value 1, otherwise, to be 0. Then transform the type of **`Drug`** to be 'int'.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XeNDEYoxrkZr"
      },
      "outputs": [],
      "source": [
        "# Question 1.5 code here\n",
        "DrugY = x\n",
        "DrugY['Drug'] = x['Drug'].replace(['DrugY', 'drugX', 'drugA', 'drugB', 'drugC'], [1,0,0,0,0])\n",
        "DrugY['Drug'] = DrugY['Drug'].astype('int')\n",
        "\n",
        "#2 pts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LORXe5nU-lL"
      },
      "source": [
        "1.6. What is the baseline accuracy for this classification problem? Round into 1 decimal place (for example, 0.2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tDl3SaGU-lL",
        "outputId": "a117a61f-b223-48cd-c8c1-1817bbb8b7c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "51.0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code here\n",
        "blA = DrugY['Drug'].sum()/len(DrugY)*100\n",
        "blA.round(1)\n",
        "#2 pts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpiZmxAtU-lQ"
      },
      "source": [
        "**YOUR ANSWER HERE:** [1pt] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svT8YoBjU-lR"
      },
      "source": [
        "## Question 2: /7 pts\n",
        "\n",
        "Split the data into train and test for the outcome/response and the predictor variables. Hold out 25% of observations as the test set.  Pass `random_state=11` to `train_test_split` to ensure you get the same train and tests sets as the solution. Your dependent variable in the the dataset is named as `Drug`. How many patients who take \"DrugY\" in the train dataset and test dataset, respectively?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZabWhfKqU-lS",
        "outputId": "cb468d19-8d2d-4df8-cec9-91830ba85f98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Users in test =  26\n",
            "Number of Users in train =  76\n"
          ]
        }
      ],
      "source": [
        "# Question 2 code here.\n",
        "X_train, X_test, y_train, y_test = train_test_split(dummies,DrugY['Drug'], random_state=11, test_size= 0.25)\n",
        "print(\"Number of Users in test = \", y_test.sum())\n",
        "print('Number of Users in train = ', y_train.sum())\n",
        "# Don't use the \"Drug\" as a feature\n",
        "\n",
        "#6 pts correct code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04g5eqFb4UHe"
      },
      "source": [
        "**YOUR ANSWER HERE:** [1pt] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUKW_K_hrz9G"
      },
      "source": [
        "Number of Users in test =  26\n",
        "\n",
        "Number of Users in train =  76"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-NwTJR2U-lU"
      },
      "source": [
        "## Question 3: /20 pts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrQkrgnKU-lV"
      },
      "source": [
        "3.1 Create a instance of sklearn's `LogisticRegression` object for **unpenalized** logistic regression.\n",
        "Using this object, **run a logisitic regression analysis** of `Drug` (y-variable) against `Age` and `Na_to_K` (x-variables) using your training data. Report the parameters (variables and intercept) of your model as indicated with the `print` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upgKwmOMU-lV",
        "outputId": "e50af42c-a9bb-4d64-9fbb-a3bbf6adf657"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intercept :  -8.72\n",
            "Variables :  [-0.0109  0.6575]\n"
          ]
        }
      ],
      "source": [
        "# Question 3 code here\n",
        "AgeNaK = X_train[['Age', 'Na_to_K']]\n",
        "regAgeNaK = LogisticRegression(penalty='none').fit(AgeNaK,y_train)\n",
        "print(\"Intercept : \",regAgeNaK.intercept_[0].round(4))\n",
        "print(\"Variables : \", regAgeNaK.coef_[0].round(4))\n",
        "#10 pts "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kheT1mJBU-lY"
      },
      "source": [
        "3.2 Compute 4 label-based criteria, namely, 'Accuracy', 'Precision', 'Sensitivity' and 'Specificity' for your two variables only classifier **using the test data** (Round into 4 decimal place). Use a threshold of 0.5. Answer the questions in this text box below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeCznyblU-la",
        "outputId": "c05e2144-4173-4ad5-cc89-6cb644736f4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tp: 25 tn: 22 fp: 2 fn: 1\n",
            "Accuracy: 0.94 Recall: 0.962 Precision: 0.926 Sensitivity: 0.962 Specificity: 0.917\n"
          ]
        }
      ],
      "source": [
        "\n",
        "## Put code here to compute criteria:\n",
        "twoV_test = X_test[['Age','Na_to_K']]\n",
        "\n",
        "#predLabel = regAgeNaK.predict(twoV_test)\n",
        "#matrix = confusion_matrix(y_test,predLabel)\n",
        "#trueNeg = matrix[1][1]\n",
        "#truePos = matrix[0][0]\n",
        "#sumCorrect = matrix[0][0]+matrix[1][1]\n",
        "#classNeg = matrix[0][1] + matrix[1][1]\n",
        "#classPos = matrix[0][0] + matrix[1][0]\n",
        "#predPos = sum(matrix[0])\n",
        "\n",
        "#accuracy = np.round(sumCorrect/len(predLabel),4)\n",
        "#precision = np.round(truePos/predPos,4)\n",
        "#sensitivity = np.round((truePos)/classPos, 4)\n",
        "#specifity =  np.round((trueNeg/classNeg),4)\n",
        "#print(\"Accuracy = \", accuracy)\n",
        "#print('Preciscion = ', precision)\n",
        "#print(\"Sensitivity = \", sensitivity)\n",
        "#print(\"Specifity = \", specifity)\n",
        "\n",
        "##from lab had own code but tas was much cleaner\n",
        "def compute_performance(yhat, y, classes):\n",
        "    \n",
        "    # First, get tp, tn, fp, fn\n",
        "    tp = sum(np.logical_and(yhat == classes[1], y == classes[1]))\n",
        "    tn = sum(np.logical_and(yhat == classes[0], y == classes[0]))\n",
        "    fp = sum(np.logical_and(yhat == classes[1], y == classes[0]))\n",
        "    fn = sum(np.logical_and(yhat == classes[0], y == classes[1]))\n",
        "\n",
        "    print(f\"tp: {tp} tn: {tn} fp: {fp} fn: {fn}\")\n",
        "    \n",
        "    # Accuracy\n",
        "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
        "    \n",
        "    # Precision\n",
        "    # \"Of the ones I labeled +, how many are actually +?\"\n",
        "    precision = tp / (tp + fp)\n",
        "    \n",
        "    # Recall\n",
        "    # \"Of all the + in the data, how many do I correctly label?\"\n",
        "    recall = tp / (tp + fn)    \n",
        "    \n",
        "    # Sensitivity\n",
        "    # \"Of all the + in the data, how many do I correctly label?\"\n",
        "    sensitivity = recall\n",
        "    \n",
        "    # Specificity\n",
        "    # \"Of all the - in the data, how many do I correctly label?\"\n",
        "    specificity = tn / (fp + tn)\n",
        "    \n",
        "    # Print results\n",
        "    \n",
        "    print(\"Accuracy:\",round(acc,3),\"Recall:\",round(recall,3),\"Precision:\",round(precision,3),\n",
        "          \"Sensitivity:\",round(sensitivity,3),\"Specificity:\",round(specificity,3))\n",
        "predProb = regAgeNaK.predict_proba(twoV_test)\n",
        "yhatD = regAgeNaK.classes_[(predProb[:,1] > 0.5).astype(int)]\n",
        "compute_performance(yhatD, y_test, regAgeNaK.classes_)\n",
        "#5 pts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RVHdh8JPU-lb"
      },
      "outputs": [],
      "source": [
        "## Put the code you need to answer the following questions.\n",
        "## derived from above\n",
        "#2 pts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUGuT8L1U-lb"
      },
      "source": [
        "* How many of the test instances are labeled positive by your classifier?\n",
        "  \n",
        "  Positive Predictions 23 \n",
        "\n",
        "* Does this classifier reach the baseline accuracy?\n",
        "\n",
        "  Yes it surpasses it by quite a bit\n",
        "\n",
        "* Is this classifier useful for classifying drug-Y? Explain in one or two sentences using the performance matrix results.\n",
        " \n",
        "  Id argue that it is useful, as it classified the majority of the test data correctly, with high rates in the label criteria. it has an accuracy that surpases the baseline \n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mq1cndaU-lc"
      },
      "source": [
        "## Question 4: /8 pts\n",
        "Now with default penalty method, fit two logistic regression models using tuning parameter $C=0.1$ and $C=1$ to the training data and include all the variables in the data frame (except for `Drug`) in the cell below. You will want to make new objects like you did for the simpler model. Print the parameters (variables and intercept) you obtain, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiH4XfJHU-le",
        "outputId": "9538982f-d74a-4d41-d71a-6bb76e2bcc3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C = 0.1 intercepts: -7.9564  variables: [-0.0131  0.6028 -0.113   0.1131 -0.2419  0.3655 -0.1236  0.2376 -0.2375]\n",
            "C = 1 intercepts: -9.925618348731234  variables: [-0.0252  0.7757 -0.2607  0.2607 -0.721   1.1849 -0.4639  0.6653 -0.6653]\n"
          ]
        }
      ],
      "source": [
        "# Code for Question 4\n",
        "decimalReg = LogisticRegression(C=0.1).fit(X_train,y_train)\n",
        "wholeReg = LogisticRegression(C=1).fit(X_train,y_train)\n",
        "print(\"C = 0.1 intercepts:\", decimalReg.intercept_[0].round(4), ' variables:', decimalReg.coef_[0].round(4))\n",
        "\n",
        "print(\"C = 1 intercepts:\", wholeReg.intercept_[0], ' variables:', wholeReg.coef_[0].round(4))\n",
        "\n",
        "#7 pts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jc2UNoYnGhD"
      },
      "source": [
        "* Describe the differences between the fitted model parameters obtained from the two models here.\n",
        "\n",
        "  The difference is that the second model has lower regulization as C set the inverse strength of regulization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMUsdjPfU-lh"
      },
      "source": [
        "## Question 5: /15 pts\n",
        "\n",
        "In the cell below, compute the 4 label-based criteria we mentioned in Question 3.2 for the two new classifiers using the test data. (You don't have to copy the function down into this cell; just call it again here.) Use a threshold of 0.5. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWsf59jcU-li",
        "outputId": "94808d06-e74f-4055-814a-60bb7b92ce0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C = 0.1\n",
            "tp: 25 tn: 24 fp: 0 fn: 1\n",
            "Accuracy: 0.98 Recall: 0.962 Precision: 1.0 Sensitivity: 0.962 Specificity: 1.0\n",
            "C = 1\n",
            "tp: 24 tn: 24 fp: 0 fn: 2\n",
            "Accuracy: 0.96 Recall: 0.923 Precision: 1.0 Sensitivity: 0.923 Specificity: 1.0\n",
            "Common positives  24\n"
          ]
        }
      ],
      "source": [
        "# Code for  Code for answering questions in the below cell\n",
        "decProb = decimalReg.predict_proba(X_test)\n",
        "wholeProb = wholeReg.predict_proba(X_test)\n",
        "decD = decimalReg.classes_[(decProb[:,1] > 0.5).astype(int)]\n",
        "wholeD = wholeReg.classes_[(wholeProb[:,1] > 0.5).astype(int)]\n",
        "print(\"C = 0.1\")\n",
        "compute_performance(decD,y_test, decimalReg.classes_)\n",
        "print(\"C = 1\")\n",
        "compute_performance(wholeD,y_test, wholeReg.classes_)\n",
        "\n",
        "totalCommonPos = sum((decimalReg.predict(X_test)==1) * (wholeReg.predict(X_test)==1))\n",
        "print(\"Common positives \",totalCommonPos)\n",
        "#9 pts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXXGvWDYU-lj"
      },
      "source": [
        "* How many of the test instances are respectively labeled positive by the two classifiers?\n",
        "\n",
        "Common positives  24 \n",
        "\n",
        "* Among the classifiers in Questions 3 and 4, which one is the **best classifier** for classifying Drug? Explain the possible reason in one or two sentences.\n",
        "\n",
        "With a 0.5 threshold I believe C = 0.1 is the best suited. As the none penalty ones its ability to predict all the negatives in the test. While the C = 1 model  struggles to get all the positives in the Test data. While both have almost every other metric lower or equl to the C= 0.1 model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtWayoFDU-lk"
      },
      "source": [
        "## Question 6: /14 pts\n",
        "In the cell below, predict the class coding your own sigmoid function (do NOT use  the predict function from sklear). Compare the first 5 rows using the three models constructed in question 4 and question 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zYNJn57U-ll",
        "outputId": "c4937b0c-f207-4432-ad71-8909abb52373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[7.64456779e-01 2.35543221e-01]\n",
            " [5.46385949e-05 9.99945361e-01]\n",
            " [5.63836104e-02 9.43616390e-01]\n",
            " [9.44101698e-01 5.58983018e-02]\n",
            " [4.12698100e-05 9.99958730e-01]]\n",
            "[[9.00832797e-01 9.91672027e-02]\n",
            " [9.96926764e-06 9.99990031e-01]\n",
            " [2.11186998e-02 9.78881300e-01]\n",
            " [9.79027263e-01 2.09727370e-02]\n",
            " [1.54277643e-06 9.99998457e-01]]\n",
            "        0\n",
            "174  0.24\n",
            "33   1.00\n",
            "173  0.94\n",
            "186  0.06\n",
            "22   1.00\n",
            "        0\n",
            "174  0.10\n",
            "33   1.00\n",
            "173  0.98\n",
            "186  0.02\n",
            "22   1.00\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "sigmoid = lambda x: 1 / (1 + np.exp(-x));\n",
        "\n",
        "decPredSig = sigmoid(decimalReg.intercept_ + X_test@decimalReg.coef_.T).round(2)\n",
        "wholePredSig = sigmoid(wholeReg.intercept_ + X_test@wholeReg.coef_.T).round(2)\n",
        "print(decProb[0:5])\n",
        "print(wholeProb[0:5])\n",
        "print( decPredSig[:5])\n",
        "print(wholePredSig[:5])\n",
        "#8 pts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HUOZPnzU-ln"
      },
      "source": [
        "* Is the probability given by the sigmoid function the probability of a case being negative?\n",
        "\n",
        "  A case is negative when the probability is less than 0.5\n",
        "\n",
        "* By just looking over the first 5 cases, how does the probabilities obtained from the two classifiers in Question 4 changes? Does the change of probability actually change the classification results for the first 5 cases?\n",
        "\n",
        "  With the probability in question 4 they stay relatively the same with some being lower or higher usualy by 0.001 at most. No in the first 5 cases the classification would still be the same"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08R44Tq-U-lo"
      },
      "source": [
        "# Question 7: /7 pts\n",
        "\n",
        "Plot ROC curves for all of your classifiers using the cells below, then answer the following questions, computing whatever quantities you need to answer them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "IGol7oXQ51Eo",
        "outputId": "6f8a5c87-ba94-44fd-fd61-c6c2a855434b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff8342d33d0>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Your code here\n",
        "NaKfpr, NaKtpr, _ = roc_curve(y_test, predProb[:,1], pos_label=regAgeNaK.classes_[1])\n",
        "decfpr, dectpr, _ = roc_curve(y_test, decProb[:,1], pos_label=decimalReg.classes_[1])\n",
        "wholefpr, wholetpr, _ = roc_curve(y_test, wholeProb[:,1], pos_label=wholeReg.classes_[1])\n",
        "ax = sns.lineplot(x = NaKfpr, y= NaKtpr)\n",
        "ax = sns.lineplot(x= decfpr, y = dectpr)\n",
        "ax = sns.lineplot(x= wholefpr,y=wholetpr)\n",
        "ax.set_xlabel(\"FP Rate\")\n",
        "ax.set_ylabel(\"TP Rate\")\n",
        "ax.set_title('ROC Curve')\n",
        "plt.legend(title='Classifier', loc='lower right', labels=['Age to NaK', 'Decimal C', 'Whole C'])\n",
        "#6 pts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS6tI4eaU-lp"
      },
      "source": [
        "* Which classifier has a highest estimated probability of correctly distinguishing between a positive and a negative instance? How do you know?\n",
        "\n",
        "  Probably decimal C as it has the highest in all the metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJp8PEW2LkY6"
      },
      "source": [
        "# Question 8: /11 pts\n",
        "\n",
        "Multiclass Logistic Regression\n",
        "\n",
        "In the classification lab, we trained a binary LR classifier using the _mnist_ dataset to discriminate entries which were equal to 5 from the rest. This time you have 10 classes i.e., 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9. Use the same dataset and `SGDClassifier` to tain a multiclass logistic regression model with `l2` regularization. For training, include these arguments too: `max_iter=2000`, `tol=1e-3`, `random_state=seed`. For computation speed-up, some `sklearn` functions take the argument `n_jobs=N` to run in parallel. A good value for N can be the number of physical CPU cores that your machine possesses. Check the documentations of the functions to take advantage from this where applicable. For splitting the data use `test_size=0.5` and `random_state=seed`.\n",
        "\n",
        "Put your classifier and the `StandardScaler()` into a pipeline using `make_pipeline`. Therefore, your final model will be a pipeline that always standardizes the data before feeding it to the classifier. Use the `classification_report` to report the performance of your final model (*i.e.*, the pipeline) over the **test set**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "ZFMB00UhLkY7",
        "outputId": "e794adf7-fb1c-45c7-bcde-ef8e8e6f1a54"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAFN0lEQVR4nO3dMUuVbRzH8ceO0ZQaBI5BYIOp0SK4pIO9grb2CMLB5oYmF41aIhobrKUhmn0LLuJQi1OSgyAGNbh4nqlBnnP/fTyl53f08xn9cZ+uii83dGEOtNvtf4A8l3p9AKAzcUIocUIocUIocUKowWN2/5QLp2+g0xe9OSGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCHUYK8PwMkcHh6W+/7+frlvb2+X+4cPH058pt9ev35d7r9+/Sr3oaGhxm15ebl89vHjx+Xej7w5IZQ4IZQ4IZQ4IZQ4IZQ4IZSrlB748eNH4/b58+fy2bW1tXJ///59V2f6G4aHh8t9bGys3K9evdq4zc/Pd3WmfubNCaHECaHECaHECaHECaHECaHECaHcc/bAixcvGrelpaUzPMl/jYyMNG63bt0qn3316lW5z8zMdHWmi8qbE0KJE0KJE0KJE0KJE0KJE0KJE0K55zwFjx49KvfV1dWuP/vKlSvlvrKyUu63b98u9+vXrzduk5OT5bP8Xd6cEEqcEEqcEEqcEEqcEEqcEEqcEGqg3W5XeznS2d27d8t9Y2Oj688eHR0t952dna4/m54Z6PRFb04IJU4IJU4IJU4IJU4IJU4IJU4I5fs5T8Fp3nM+efKk62fpL96cEEqcEEqcEEqcEEqcEEqcEMpVyim4f/9+ub97965xGxys/0rm5+e7ORJ9yJsTQokTQokTQokTQokTQokTQokTQrnnDNNqtcp9ZmbmjE5Cr3lzQihxQihxQihxQihxQihxQihxQihxQihxQihxQihxQihxQihxQihxQihxQihxQihxQihxQihxQihxQihxQihxQihxQqiBdrtd7eVIZ7u7u+U+NTXVuO3t7ZXPfvnypdxv3rxZ7kQa6PRFb04IJU4IJU4IJU4IJU4IJU4I5SqlB27cuNG4ffv2rXx2dHS03K9du9bVmX57+PBh47awsFA+OzIy8ke/9gXmKgX6iTghlDghlDghlDghlDghlDghlHvOHnjw4EHj9unTpzM8ycnMzc2V+/Pnz8t9dnb2L57mXHHPCf1EnBBKnBBKnBBKnBBKnBBKnBDKPWcPHB4eNm4vX74sn52YmCj39fX1cv/48WO5b25ulntlcXGx3I/7vV1g7jmhn4gTQokTQokTQokTQokTQokTQrnnvGB2dnbK/d69e43b1tZW+eydO3fK/bg72FarVe7nmHtO6CfihFDihFDihFDihFDihFCuUjji7du3jdvTp0/LZw8ODv5ov3z5crmfY65SoJ+IE0KJE0KJE0KJE0KJE0KJE0K55+R/Gx8fL/evX7+Wu3vORu45oZ+IE0KJE0KJE0KJE0KJE0KJE0IN9voAZPn+/Xvj9vPnzzM8Cd6cEEqcEEqcEEqcEEqcEEqcEEqcEMo9J0e8efOmcdve3i6fnZycLPdLl7wLTsKfFoQSJ4QSJ4QSJ4QSJ4QSJ4QSJ4Ryz8kR09PTXT/77Nmzcm+1Wl1/9kXkzQmhxAmhxAmhxAmhxAmhxAmh/AhA6D0/AhD6iTghlDghlDghlDghlDghlDghlDghlDghlDghlDghlDghlDghlDghlDgh1HH/NWbH7zMDTp83J4QSJ4QSJ4QSJ4QSJ4QSJ4T6F0nUqbtoDaDpAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn import pipeline\n",
        "# code here\n",
        "import matplotlib as mpl\n",
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "def plot_digit(data):\n",
        "    image = data.reshape(28, 28)\n",
        "    plt.imshow(image, cmap = mpl.cm.binary,interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")\n",
        "plot_digit(X[100])\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y.astype('int'), test_size=0.5, random_state=seed)\n",
        "sgd_model = SGDClassifier(penalty='l2', max_iter=2000, tol=1e-3,random_state=seed, n_jobs=4).fit(Xtrain,ytrain)\n",
        "\n",
        "#9 pts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaeLWe7WoQze",
        "outputId": "8465000f-6a8f-400c-a1c7-272f52174a21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.90      0.94      3535\n",
            "           1       0.95      0.97      0.96      3954\n",
            "           2       0.86      0.89      0.87      3475\n",
            "           3       0.83      0.88      0.85      3546\n",
            "           4       0.90      0.91      0.90      3386\n",
            "           5       0.63      0.91      0.74      3158\n",
            "           6       0.97      0.89      0.93      3389\n",
            "           7       0.87      0.94      0.90      3652\n",
            "           8       0.90      0.57      0.70      3392\n",
            "           9       0.90      0.80      0.85      3513\n",
            "\n",
            "    accuracy                           0.87     35000\n",
            "   macro avg       0.88      0.87      0.87     35000\n",
            "weighted avg       0.88      0.87      0.87     35000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "scaleModel = StandardScaler().fit(Xtrain, ytrain)\n",
        "report = classification_report(ytest,sgd_model.predict(Xtest))\n",
        "pipeline = make_pipeline(scaleModel, sgd_model)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKd0SlfwLkY7"
      },
      "source": [
        "Let's see how the model generalizes to new data.\n",
        "\n",
        "You can run the cell below to see how well your model can recognize a digit written by the mouse cursor. Set the `final_model` variable according to the name choses for your pipeline, run the cell, draw on the pop-up canvas, and once you close the canvas you will see the result.\n",
        "\n",
        "This code will not work on headless servers such as Colab. You need to install the `tk-tools` package and run it locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "sxvdfYxtLkY7",
        "outputId": "b63ba7f2-8f46-4401-fdb4-6bbda3c57062"
      },
      "outputs": [],
      "source": [
        "final_model = pipeline  # here use the name of your pipeline\n",
        "\n",
        "#!pip install tk-tools\n",
        "from tkinter import *\n",
        "import tkinter as tk\n",
        "from PIL import Image\n",
        "import io\n",
        "import matplotlib as mpl\n",
        "\n",
        "temp_file_name=\"TEMP_image_TEMP.jpg\"\n",
        "\n",
        "app = Tk()\n",
        "app.geometry(\"300x300\")\n",
        "\n",
        "canvas = tk.Canvas(app, bg='white')\n",
        "canvas.pack(anchor='nw', fill='both', expand=1)\n",
        "\n",
        "def get_x_and_y(event):\n",
        "    global lasx, lasy\n",
        "    lasx, lasy = event.x, event.y\n",
        "\n",
        "def draw_smth(event):\n",
        "    global lasx, lasy\n",
        "    canvas.create_line((lasx, lasy, event.x, event.y), fill='red', width=3.5)\n",
        "    lasx, lasy = event.x, event.y\n",
        "    ps = canvas.postscript(colormode = 'color')\n",
        "    img = Image.open(io.BytesIO(ps.encode('utf-8')))\n",
        "    img.save(temp_file_name)\n",
        "\n",
        "canvas.bind(\"<Button-1>\", get_x_and_y)\n",
        "canvas.bind(\"<B1-Motion>\", draw_smth)\n",
        "\n",
        "app.mainloop()\n",
        "\n",
        "img = Image.open(temp_file_name)\n",
        "#resize image to 28x28 pixels\n",
        "img = img.resize((28,28))\n",
        "#convert rgb to grayscale\n",
        "img = img.convert(\"L\")\n",
        "img = np.array(img)\n",
        "img = 255.0 - img\n",
        "print(\"Your input:\")\n",
        "plt.imshow(img, cmap = mpl.cm.binary); plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# reshaping to support our model input\n",
        "img = np.reshape(img, 28*28)\n",
        "#predicting the class\n",
        "print('Input recognized as ' + str(final_model.predict([img])[0])+'.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX5xfT6kLkY8"
      },
      "source": [
        "* Despite showing great scores in training and testing stages, why your model does not generalize well to new data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W60Qphn3LkY8"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "If i had to guess its because it is analysing to many features, that are just the intensity of each pixel which makes it accurate only in respect to the test data.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7 (default, Oct 13 2021, 06:45:31) \n[Clang 13.0.0 (clang-1300.0.29.3)]"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
