{"cells":[{"cell_type":"markdown","metadata":{"id":"_Lhvu0GdViwG"},"source":["# Assignment 04: Constructing Confidence Interval\n","\n","Once you are finished, ensure to complete the following steps.\n","1.  Restart your kernel by clicking 'Kernel' > 'Restart & Run All'.\n","2.  Fix any errors which result from this.\n","3.  Repeat steps 1. and 2. until your notebook runs without errors.\n","4.  Submit your completed notebook to OWL by the deadline."]},{"cell_type":"markdown","metadata":{"id":"sUPKHUcmViwT"},"source":["## Preliminaries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eoRkDjgKViwX"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from scipy.stats import t\n","import matplotlib.pyplot as plt\n","seed=1110\n","np.random.seed(seed)"]},{"cell_type":"markdown","metadata":{"id":"076P9zOgViwb"},"source":["## Question 1 - <span style=\"color:green\">[100]</span>\n","You are going to work on a dataset which lists some features of the soccer players participated in the 2022 FIFA World Cup. We want to predict the players value and quantify the uncertainty of our prediction using what we learnt in week 4. The dataset has the following attributes:\n","- `Age`: Player age in years\n","- `Overall`: Player overall performance score (higher better)\n","- `Potential`: Player potential score (higher better)\n","- `Value`: Player value *i.e*, the amount of money in euros a club should pay in order to purchase the player (higher better)\n","- `Wage`: Player stipend in euros (higher better)\n","- `Preferred Foot`: Player preferred foot to play\n","- `International Reputation`: Player international fame (higher better)\n","- `Week Foot`: Performance score of player weak foot (higher better)\n","- `Skill Moves`: Player move skill score (higher better)\n","- `Body Type`: Player body type\n","- `Position`: Position player holds on the pitch\n","- `Height`: Player height in centimeters\n","- `Weight`: Player weight in kilograms\n","\n","Therefore the target is `Value`."]},{"cell_type":"markdown","metadata":{"id":"OPPmZeT-Viwi"},"source":["### Q 1.1 - <span style=\"color:red\">[1]</span> - Load `data.csv` and show the first 5 rows."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rydQoN0bViwl"},"outputs":[],"source":["#"]},{"cell_type":"markdown","source":["### Q 1.2 - <span style=\"color:red\">[3]</span> - Use a pandas relevant method to reveal `Dtype` of the features and indicate whether the date set has any `Null` values. "],"metadata":{"id":"Bb9EYbkYd4J9"}},{"cell_type":"code","source":["#"],"metadata":{"id":"-A3VkWusd4x5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### *Written Answer:*\n"],"metadata":{"id":"2K0p2l7GkOJZ"}},{"cell_type":"markdown","source":["### Q 1.3 - <span style=\"color:red\">[3]</span> - Use a pandas relevant method to get a summary statistics of the data and inspect it. Which features have the lowest and highest standard deviation respectively? What was the age of the youngest player in the World Cup? "],"metadata":{"id":"K2ei527ecgpm"}},{"cell_type":"code","source":["#"],"metadata":{"id":"cTRW8jnAcf7k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### *Written Answer:*\n"],"metadata":{"id":"8TdZHEjLdNLT"}},{"cell_type":"markdown","source":["### Q 1.4 - <span style=\"color:red\">[4]</span> - Use a pandas relevant method to see the distribution of the numerical features all in one plot window. Which ones look like Gaussian?"],"metadata":{"id":"oMojKpCFe4Wg"}},{"cell_type":"code","source":["#"],"metadata":{"id":"-hVLm4Nye46J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### *Written Answer:*\n"],"metadata":{"id":"wWcCZ2vpi2bT"}},{"cell_type":"markdown","metadata":{"id":"9IDD-XCpViwp"},"source":["### Q 1.5 - <span style=\"color:red\">[2]</span> - Perform one hot encoding to prepare the categorical values for linear regression."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7p_xduNiViwr"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"P7OYh1g3Viww"},"source":["### Q 1.6 - <span style=\"color:red\">[4]</span> - Use `seaborn.jointplot` to investigate the relationship between `Overall` and `Value` as well as `Wage` and `Value`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ytGHieW7Viw0"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"47Eoo9KkViw4"},"source":["### Q 1.7 - <span style=\"color:red\">[8]</span> - Where applicable, use logarithm function to transform either `Overall`, `Wage`, or `Value` to make them better fit the assumptions of linear regression. `Joinplot` the transformed versions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mo7gl2-xViw8"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"fPGdEciaViw-"},"source":["### Q 1.8 - <span style=\"color:red\">[4]</span> - Add the transformed version of the variables which you chose to transform as new columns to your dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oaei9jJ1VixA"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"HliTsGBtVixC"},"source":["### Q 1.9 - <span style=\"color:red\">[4]</span> - Use `pandas.corr()` to output the pairwise correlation between every feature and the target."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H9Gx9SpjVixE"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"Fivi2OQJVixG"},"source":["### Q 1.10 - <span style=\"color:red\">[4]</span> - What are the most positively and negatively correlated features? How do you interpret the positive and negative correlations?"]},{"cell_type":"markdown","metadata":{"id":"x_32K8GzVixH"},"source":["#### *Written Answer:*\n"]},{"cell_type":"markdown","metadata":{"id":"JqxVzYnhVixL"},"source":["### Q 1.11 - <span style=\"color:red\">[15]</span> - Let's train a model to predict player `Value` using all features except some (Hint: think about those which you transformed)\n","1. This time instead of R-squared, use the `mean_squared_error` to calculate Root Mean Squared Error (RMSE) as your model scorer\n","2. Split the data into train and test with `test_size=0.2, random_state=seed`\n","3. Pick `LinearRegression()` from sklearn as your model\n","4. Report both prediction (*i.e.*, on training set) and generalization (*i.e.*, on test set) RMSE scores of your model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ALUaJg1SVixY"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"IiLVJDm-Vixc"},"source":["### Q 1.12 - <span style=\"color:red\">[8]</span> - Scatter plot `Overall` vs true `Value` as well as `Overall` vs predicted `Value` in the same graph window over the test set. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3kup9-zZVixd"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"hYimk6xBVixh"},"source":["### Q 1.13 - <span style=\"color:red\">[15]</span> - Calculate confidence interval (based on 99% confidence level) for mean `Value` by bootstrapping. For this purpose, code a bootstrap function that in each bootstrap iteration, samples from the training set to fit the linear regression model and uses the test set to make predictions - therefore your bootstrap statistic is the average of the predictions over the test set. Your function must take as input arguments: your model, Xtrain, ytrain, Xtest, and numboot=100. The function must return only one object that is the array of recorded values for the bootstrap statistic."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bs8AhoNCVixj"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"_aKrOrfKVixo"},"source":["### Q 1.14 - <span style=\"color:red\">[6]</span> - Construct a 99% confidence interval using the Central Limit Theorem. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLcpZuqDVixq"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"HUqKfd0cVixs"},"source":["### Q 1.15 - <span style=\"color:red\">[10]</span> - We want to see the effect of sample size ($n$) on the CI calculated from CLT. Write a `for` loop which in each iteration randomly samples from your \"sample statistic\" and calculates and stores the width (*i.e.*, $\\mid$ Upper Bound - Lower Bound $\\mid$) of the corresponding CI in an array. Obviously, you should start from a small $n$ and increase it per iteration (step size up to you). After the loop, plot sample size (*i.e.*, $n$) against the CI widths and explain your observation in one sentence."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z_ZtT_HYVixt"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"Ew7H8K4PVixv"},"source":["#### *Written Answer:*\n"]},{"cell_type":"markdown","metadata":{"id":"dViR9sbGVixw"},"source":["### Q 1.16 - <span style=\"color:red\">[6]</span> - Randomly subsample your \"sample statistic\" with $n=30$ and calculate $t$-based 99% CI. Is it a good idea to calculate CI for this data set this way? Why?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_GACneM5Vixx"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"hQNPi8YeVix0"},"source":["#### *Written Answer:*\n"]},{"cell_type":"markdown","metadata":{"id":"erK7028PVix1"},"source":["### Q 1.17 - <span style=\"color:red\">[3]</span> -  What method would be your ultimate choice for calculating CI for this problem? Why?"]},{"cell_type":"markdown","metadata":{"id":"lbJQXwq5Vix6"},"source":["#### *Written Answer:*\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"3420a8792bbc8a921cecec9f5e200567f9d5b83365a03086ee32a665b051d9eb"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}